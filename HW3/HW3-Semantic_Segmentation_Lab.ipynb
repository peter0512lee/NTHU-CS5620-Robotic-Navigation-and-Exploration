{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3-Semantic_Segmentation_Lab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VwfKhFfHF27m"},"source":["# Semantic Segmentation with PyTorch"]},{"cell_type":"markdown","metadata":{"id":"qGeguvkAGNlw"},"source":["Mount google drive to colab."]},{"cell_type":"code","metadata":{"id":"RHc49hWDOJKw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651749650386,"user_tz":-480,"elapsed":2561,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}},"outputId":"4f316925-26a9-4f41-d070-2f2ccaa477a5"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"Jly0ouf9eNOQ"},"source":["Import neccessary libraties and set parameters."]},{"cell_type":"code","metadata":{"id":"Qzie3tp6QThn","executionInfo":{"status":"ok","timestamp":1651749650933,"user_tz":-480,"elapsed":550,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["import os\n","import time\n","import json\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyGTWuMwngPV","executionInfo":{"status":"ok","timestamp":1651749650933,"user_tz":-480,"elapsed":3,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["project_name = \"HW3\"\n","project_path = \"/content/drive/My Drive/\" + project_name\n","train_dataset_path = project_path + \"/SimulationDataset/train\"\n","test_dataset_path = project_path + \"/SimulationDataset/test\"\n","\n","model_type = \"unet\" # encdec / fcn / unet / pspnet\n","\n","# Create folder to store training results.\n","if model_type == \"encdec\":\n","    results_path = project_path + \"/results_encdec\"\n","elif model_type == \"fcn\":\n","    results_path = project_path + \"/results_fcn\"\n","elif model_type == \"unet\":\n","    results_path = project_path + \"/results_unet\"\n","elif model_type == \"pspnet\":\n","    results_path = project_path + \"/results_pspnet\"\n","\n","if os.path.isdir(results_path) == False:\n","   os.mkdir(results_path)\n","\n","# Parameters\n","num_class = 3 \n","input_h, input_w = 256, 256\n","batch_size = 16\n","epochs = 10\n","lr = 1e-4\n","use_gpu = torch.cuda.is_available()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nphF6DjpeZVB"},"source":["## Simulation Dataset"]},{"cell_type":"code","metadata":{"id":"HEgjfY74izJR","executionInfo":{"status":"ok","timestamp":1651749650933,"user_tz":-480,"elapsed":2,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["class SimDataset(Dataset):\n","    def __init__(self, path, n_class=num_class, flip_rate=0.5, train=True):\n","        self.img_folder_path = path + \"/img\"\n","        self.label_folder_path = path + \"/label\"\n","        self.file_list = os.listdir(self.img_folder_path)\n","        self.n_class = n_class\n","        self.flip_rate = flip_rate\n","        self.train = train\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_folder_path + \"/\" + self.file_list[idx]\n","        label_path = self.label_folder_path + \"/\" + \"jetbot_\" + self.file_list[idx].split(\"_\")[1] + \"_layer.png\"\n","\n","        # open image data\n","        img = np.asarray(Image.open(img_path).resize((256, 256), Image.NEAREST))\n","        img = img.astype(float)/255.0\n","        label_img = np.asarray(Image.open(label_path).resize((256, 256), Image.NEAREST))\n","        label = np.zeros((img.shape[0], img.shape[1], self.n_class), dtype=float)\n","        label[label_img[:,:,0]==178,0] = 1\n","        label[label_img[:,:,0]==255,1] = 1\n","        label[label_img[:,:,0]==0,2] = 1\n","\n","        if np.random.sample() < self.flip_rate:\n","            img = np.fliplr(img)\n","            label = np.fliplr(label)\n","\n","        img = torch.from_numpy(img.copy()).float()\n","        img = img.permute(2,0,1)\n","        label = torch.from_numpy(label.copy()).float()\n","        label = label.permute(2,0,1)\n","        sample = {\"X\": img, \"Y\": label}\n","        return sample\n","\n","# Load dataset\n","train_data = SimDataset(path=train_dataset_path, flip_rate=0.5)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n","test_data = SimDataset(path=test_dataset_path, flip_rate=0.0)\n","test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKvpt9GTefaL"},"source":["## Network Model\n","### VGG16 Feature Extractor (pretrained)"]},{"cell_type":"code","metadata":{"id":"CUfJoO8e-rrB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651749656762,"user_tz":-480,"elapsed":5831,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}},"outputId":"8b5935b3-0213-490e-a5ea-d9dee6db9608"},"source":["class Vgg16(nn.Module):\n","    def __init__(self, pretrained = True):\n","        super(Vgg16, self).__init__()\n","        self.vggnet = models.vgg16(pretrained)\n","        del(self.vggnet.classifier) # Remove fully connected layer to save memory.\n","        features = list(self.vggnet.features)\n","        self.layers = nn.ModuleList(features).eval() \n","        \n","    def forward(self, x):\n","        results = []\n","        for ii,model in enumerate(self.layers):\n","            x = model(x)\n","            if ii in [3,8,15,22,29]:\n","                results.append(x) #(64,256,256),(128,128,128),(256,64,64),(512,32,32),(512,16,16)\n","        return results\n","\n","vgg_model = Vgg16()\n","vgg_model = vgg_model.cuda()\n","print(vgg_model.layers)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["ModuleList(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU(inplace=True)\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU(inplace=True)\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU(inplace=True)\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU(inplace=True)\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (11): ReLU(inplace=True)\n","  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU(inplace=True)\n","  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): ReLU(inplace=True)\n","  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (18): ReLU(inplace=True)\n","  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (20): ReLU(inplace=True)\n","  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (22): ReLU(inplace=True)\n","  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (25): ReLU(inplace=True)\n","  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (27): ReLU(inplace=True)\n","  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (29): ReLU(inplace=True)\n","  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"10fl6vwtE2Dz"},"source":["### Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"CVmJVvvj1W9H","executionInfo":{"status":"ok","timestamp":1651749656762,"user_tz":-480,"elapsed":8,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["class DeConv2d(nn.Module):\n","    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, dilation):\n","        super().__init__()\n","        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n","        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n","    \n","    def forward(self, x):\n","        output = self.up(x)\n","        output = self.conv(output)\n","        return output\n","\n","class EncoderDecoder(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        pre_output = self.pretrained_net(x)\n","        output = self.bn1(self.relu(self.deconv1(pre_output[4]))) #(512,32,32)\n","        output = self.bn2(self.relu(self.deconv2(output))) #(256,64,64)\n","        output = self.bn3(self.relu(self.deconv3(output))) #(128,128,128)\n","        output = self.bn4(self.relu(self.deconv4(output))) #(64,256,256)\n","        output = self.classifier(output)\n","        return output"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-J1MWQfewD9"},"source":["### Fully Convolution Network (FCN)\n"]},{"cell_type":"code","metadata":{"id":"MjZ4-8X1EzFv","executionInfo":{"status":"ok","timestamp":1651749656763,"user_tz":-480,"elapsed":9,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["class FCN(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","        #####################################\n","        #TODO\n","        #####################################\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        #####################################\n","        pre_output = self.pretrained_net(x)\n","        output = self.bn1(self.relu(self.deconv1(pre_output[4])))   # (512, 32, 32)\n","        output = torch.add(output, pre_output[3])\n","        output = self.bn2(self.relu(self.deconv2(output)))          # (256, 64, 64)\n","        output = torch.add(output, pre_output[2])\n","        output = self.bn3(self.relu(self.deconv3(output)))          # (128, 128, 128)\n","        output = torch.add(output, pre_output[1])\n","        output = self.bn4(self.relu(self.deconv4(output)))          # (64, 256, 256)\n","        output = torch.add(output, pre_output[0])\n","        output = self.classifier(output)\n","        return output"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5xIH1GffFXP"},"source":["### U-Net"]},{"cell_type":"code","metadata":{"id":"ZbAKDtkwJQH7","executionInfo":{"status":"ok","timestamp":1651749656763,"user_tz":-480,"elapsed":9,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["class UNet(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","        #####################################\n","        #TODO\n","        #####################################\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512 * 2, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256 * 2, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128 * 2, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64 * 2, n_class, kernel_size=1)\n","    \n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        #####################################\n","        pre_output = self.pretrained_net(x)\n","        output = self.bn1(self.relu(self.deconv1(pre_output[4])))   # (512, 32, 32)\n","        # pre_output_3 = self.bn1(self.relu(self.deconv1(pre_output[3])))\n","        output = torch.cat([output, pre_output[3]], dim=1)\n","        output = self.bn2(self.relu(self.deconv2(output)))          # (256, 64, 64)\n","        # pre_output_2 = self.bn1(self.relu(self.deconv1(pre_output[2])))\n","        output = torch.cat([output, pre_output[2]], dim=1)\n","        output = self.bn3(self.relu(self.deconv3(output)))          # (128, 128, 128)\n","        # pre_output_1 = self.bn1(self.relu(self.deconv1(pre_output[1])))\n","        output = torch.cat([output, pre_output[1]], dim=1)\n","        output = self.bn4(self.relu(self.deconv4(output)))          # (64, 256, 256)\n","        # pre_output_0 = self.bn1(self.relu(self.deconv1(pre_output[0])))\n","        output = torch.cat([output, pre_output[0]], dim=1)\n","        output = self.classifier(output)\n","        return output"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwISqBr0yMTQ"},"source":["### PSPNet"]},{"cell_type":"code","metadata":{"id":"ttK5Y9AuyJ7y","executionInfo":{"status":"ok","timestamp":1651749656763,"user_tz":-480,"elapsed":8,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["class PSPNet(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        #####################################\n","        #TODO\n","        #####################################\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.ppm_size = (16, 16)\n","        self.ppm_channel = 512\n","        self.ppm_psize = [1, 2, 3, 6]\n","\n","        self.ppm_pool, self.ppm_conv, self.ppm_up = [], [], []\n","        for psize in self.ppm_psize:\n","            self.ppm_pool.append(nn.AdaptiveAvgPool2d((psize, psize)))\n","            self.ppm_conv.append(nn.Conv2d(int(self.ppm_channel), int(self.ppm_channel/len(self.ppm_psize)), kernel_size=1))\n","            self.ppm_up.append(nn.Upsample(size=self.ppm_size, mode='bilinear', align_corners=True))\n","        \n","        self.ppm_pool = nn.ModuleList(self.ppm_pool)\n","        self.ppm_conv = nn.ModuleList(self.ppm_conv)\n","        self.ppm_up = nn.ModuleList(self.ppm_up)\n","\n","        self.deconv1 = DeConv2d(1024, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        #####################################\n","        pre_output = self.pretrained_net(x)\n","        ppm_list = [pre_output[4]]\n","        for i in range(len(self.ppm_psize)):\n","            output = self.ppm_pool[i](pre_output[4])\n","            output = self.ppm_conv[i](output)\n","            output = self.ppm_up[i](self.relu(output))\n","            ppm_list.append(output)\n","        output = torch.cat(ppm_list, 1)\n","        output = self.bn1(self.relu(self.deconv1(output)))          # (512, 32, 32)\n","        output = torch.add(output, pre_output[3])\n","        output = self.bn2(self.relu(self.deconv2(output)))          # (256, 64, 64)\n","        output = torch.add(output, pre_output[2])\n","        output = self.bn3(self.relu(self.deconv3(output)))          # (128, 128, 128)\n","        output = torch.add(output, pre_output[1])\n","        output = self.bn4(self.relu(self.deconv4(output)))          # (64, 256, 256)\n","        output = torch.add(output, pre_output[0])\n","        output = self.classifier(output)\n","\n","        return output"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjcje1cPfIYs"},"source":["Construct models."]},{"cell_type":"code","metadata":{"id":"oj3Ng3mi1deU","executionInfo":{"status":"ok","timestamp":1651749657382,"user_tz":-480,"elapsed":627,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["if model_type == \"encdec\":\n","    seg_model = EncoderDecoder(pretrained_net=vgg_model, n_class=num_class)\n","elif model_type == \"fcn\":\n","    seg_model = FCN(pretrained_net=vgg_model, n_class=num_class)\n","elif model_type == \"unet\":\n","    seg_model = UNet(pretrained_net=vgg_model, n_class=num_class)\n","elif model_type == \"pspnet\":\n","    seg_model = PSPNet(pretrained_net=vgg_model, n_class=num_class)\n","\n","seg_model = seg_model.cuda()\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(seg_model.parameters(), lr=lr)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9beJVr7yfNKT"},"source":["## Training and Validation"]},{"cell_type":"code","metadata":{"id":"pQtApd8vLCa8","executionInfo":{"status":"ok","timestamp":1651749657382,"user_tz":-480,"elapsed":2,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["def train(seg_model, train_loader, test_loader):\n","    # pixel accuracy and mIOU list \n","    pixel_acc_list = []\n","    mIOU_list = []\n","    for epoch in range(1, epochs+1):\n","        ts = time.time()\n","        for iter, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            inputs, labels = batch[\"X\"], batch[\"Y\"]\n","            if use_gpu:\n","              inputs = inputs.cuda()\n","              labels = labels.cuda()\n","\n","            outputs = seg_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if iter % 10 == 0:\n","                print(\"epoch:{:2}, iter:{:2}, loss: {:.4f}\".format(epoch, iter, loss.data.item()))\n","        \n","        print(\"Finish epoch:{:2}, time elapsed: {:.4f}\".format(epoch, time.time() - ts))\n","        \n","        print(\"Start evaluation ...\")\n","        acc, iou = eval(seg_model, test_loader)\n","        pixel_acc_list.append(acc)\n","        mIOU_list.append(iou)\n","\n","        print(\"Output test results ...\")\n","        file_name = results_path + \"/\" + str(epoch).zfill(3) + \".jpg\"\n","        for iter, batch in enumerate(test_loader):\n","          inputs, labels = batch[\"X\"], batch[\"Y\"]\n","          if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","          outputs = seg_model(inputs)\n","          save_result(file_name, inputs, labels, outputs)\n","          break\n","        \n","        print(\"Save model ...\")\n","        model_path = results_path + \"/\" + \"segnet.pt\"\n","        torch.save(seg_model.state_dict(), model_path)\n","        print(\"========================================\")\n","        \n","    highest_pixel_acc = max(pixel_acc_list)\n","    highest_mIOU = max(mIOU_list)\n","    \n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n","    \n","    # Extract evaluation record\n","    record_path = results_path + \"/record.json\"\n","    ret = json.dumps({\"acc\":pixel_acc_list, \"iou\":mIOU_list})\n","    with open(record_path, 'w') as fp:\n","        fp.write(ret)\n","    \n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch+1))\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch+1))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DtvW9ZqJnmLE","executionInfo":{"status":"ok","timestamp":1651749657382,"user_tz":-480,"elapsed":2,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"source":["def eval(seg_model, test_loader):\n","    seg_model.eval()\n","    total_ious = []\n","    pixel_accs = []\n","\n","    for iter, batch in enumerate(test_loader): ## batch is 1 in this case\n","        inputs = torch.FloatTensor(batch[\"X\"])\n","        if use_gpu:\n","          inputs = inputs.cuda()\n","\n","        output = seg_model(inputs)\n","        \n","        # only save the 1st image for comparison\n","        if iter == 0:\n","            # generate images\n","            input_np = batch[\"X\"][0].data.cpu().numpy().transpose(1,2,0)\n","            output_np = output[0].data.cpu().numpy().transpose(1,2,0)\n","            gt_np = batch[\"Y\"][0].data.cpu().numpy().transpose(1,2,0)\n","        output = output.data.cpu().numpy()\n","\n","        N, _, h, w = output.shape\n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)\n","        target = batch['Y'].data.cpu().numpy().transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)\n","\n","        for p, t in zip(pred, target):\n","            total_ious.append(iou(p, t))\n","            pixel_accs.append(pixel_acc(p, t))\n","\n","    # Calculate average IoU\n","    total_ious = np.array(total_ious).T  # n_class * val_len\n","    ious = np.nanmean(total_ious, axis=1)\n","    pixel_accs = np.array(pixel_accs).mean()\n","    print(\"pix_acc: {:.4f}, meanIoU: {:.4f}\".format(pixel_accs, np.nanmean(ious)))\n","    return pixel_accs, np.nanmean(ious)\n","\n","# Calculates class intersections over unions\n","def iou(pred, target):\n","    ious = []\n","    for cls in range(num_class):\n","        pred_inds = pred == cls\n","        target_inds = target == cls\n","        intersection = pred_inds[target_inds].sum()\n","        union = pred_inds.sum() + target_inds.sum() - intersection\n","        if union == 0:\n","            ious.append(float(\"nan\")) # if there is no ground truth, do not include in evaluation\n","        else:\n","            ious.append(float(intersection) / max(union, 1))\n","    return ious\n","\n","def pixel_acc(pred, target):\n","    correct = (pred == target).sum()\n","    total = (target == target).sum()\n","    return correct / total\n","\n","def save_result(file_name, input, label, output, n_samples=3):\n","    input_np = input[:n_samples].data.cpu().numpy().transpose(0,2,3,1)\n","    label_np = label[:n_samples].data.cpu().numpy().transpose(0,2,3,1)\n","    output_np = output[:n_samples].data.cpu().numpy().transpose(0,2,3,1)\n","    \n","    result_list = []\n","    for k in range(n_samples):\n","        tmp = np.zeros([256,256,3], dtype=np.float32)\n","        for i in range(256):\n","            for j in range(256):\n","                tmp[i,j,output_np[k][i,j].argmax()] = 1\n","        result = np.hstack((input_np[k], label_np[k], tmp))\n","        result_list.append(result)\n","\n","    # horizontally stack original image and its corresponding segmentation results\n","    vstack_image = np.vstack(result_list)\n","    new_im = Image.fromarray(np.uint8(vstack_image*255))\n","    new_im.save(file_name)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q80RO6M5JmE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651753252823,"user_tz":-480,"elapsed":3595442,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}},"outputId":"26a4f216-59c0-4cc0-cafe-9af9f94c7571"},"source":["# perform training \n","train(seg_model, train_loader, test_loader)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, iter: 0, loss: 0.7302\n","epoch: 1, iter:10, loss: 0.3157\n","epoch: 1, iter:20, loss: 0.2540\n","epoch: 1, iter:30, loss: 0.2194\n","epoch: 1, iter:40, loss: 0.1918\n","epoch: 1, iter:50, loss: 0.1677\n","epoch: 1, iter:60, loss: 0.1480\n","epoch: 1, iter:70, loss: 0.1326\n","epoch: 1, iter:80, loss: 0.1188\n","epoch: 1, iter:90, loss: 0.1178\n","epoch: 1, iter:100, loss: 0.0977\n","epoch: 1, iter:110, loss: 0.0911\n","epoch: 1, iter:120, loss: 0.0833\n","Finish epoch: 1, time elapsed: 306.8669\n","Start evaluation ...\n","pix_acc: 0.9913, meanIoU: 0.9841\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 2, iter: 0, loss: 0.0806\n","epoch: 2, iter:10, loss: 0.0388\n","epoch: 2, iter:20, loss: 0.0159\n","epoch: 2, iter:30, loss: 0.0158\n","epoch: 2, iter:40, loss: 0.0113\n","epoch: 2, iter:50, loss: 0.0086\n","epoch: 2, iter:60, loss: 0.0068\n","epoch: 2, iter:70, loss: 0.0087\n","epoch: 2, iter:80, loss: 0.0083\n","epoch: 2, iter:90, loss: 0.0048\n","epoch: 2, iter:100, loss: 0.0051\n","epoch: 2, iter:110, loss: 0.0053\n","epoch: 2, iter:120, loss: 0.0049\n","Finish epoch: 2, time elapsed: 331.1078\n","Start evaluation ...\n","pix_acc: 0.9932, meanIoU: 0.9863\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 3, iter: 0, loss: 0.0040\n","epoch: 3, iter:10, loss: 0.0058\n","epoch: 3, iter:20, loss: 0.0047\n","epoch: 3, iter:30, loss: 0.0050\n","epoch: 3, iter:40, loss: 0.0045\n","epoch: 3, iter:50, loss: 0.0037\n","epoch: 3, iter:60, loss: 0.0047\n","epoch: 3, iter:70, loss: 0.0039\n","epoch: 3, iter:80, loss: 0.0048\n","epoch: 3, iter:90, loss: 0.0051\n","epoch: 3, iter:100, loss: 0.0034\n","epoch: 3, iter:110, loss: 0.0039\n","epoch: 3, iter:120, loss: 0.0033\n","Finish epoch: 3, time elapsed: 329.4503\n","Start evaluation ...\n","pix_acc: 0.9937, meanIoU: 0.9868\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 4, iter: 0, loss: 0.0029\n","epoch: 4, iter:10, loss: 0.0032\n","epoch: 4, iter:20, loss: 0.0034\n","epoch: 4, iter:30, loss: 0.0039\n","epoch: 4, iter:40, loss: 0.0028\n","epoch: 4, iter:50, loss: 0.0031\n","epoch: 4, iter:60, loss: 0.0026\n","epoch: 4, iter:70, loss: 0.0027\n","epoch: 4, iter:80, loss: 0.0030\n","epoch: 4, iter:90, loss: 0.0029\n","epoch: 4, iter:100, loss: 0.0032\n","epoch: 4, iter:110, loss: 0.0024\n","epoch: 4, iter:120, loss: 0.0025\n","Finish epoch: 4, time elapsed: 329.5620\n","Start evaluation ...\n","pix_acc: 0.9938, meanIoU: 0.9873\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 5, iter: 0, loss: 0.0027\n","epoch: 5, iter:10, loss: 0.0022\n","epoch: 5, iter:20, loss: 0.0022\n","epoch: 5, iter:30, loss: 0.0028\n","epoch: 5, iter:40, loss: 0.0026\n","epoch: 5, iter:50, loss: 0.0028\n","epoch: 5, iter:60, loss: 0.0025\n","epoch: 5, iter:70, loss: 0.0026\n","epoch: 5, iter:80, loss: 0.0019\n","epoch: 5, iter:90, loss: 0.0027\n","epoch: 5, iter:100, loss: 0.0026\n","epoch: 5, iter:110, loss: 0.0021\n","epoch: 5, iter:120, loss: 0.0022\n","Finish epoch: 5, time elapsed: 329.6119\n","Start evaluation ...\n","pix_acc: 0.9939, meanIoU: 0.9872\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 6, iter: 0, loss: 0.0024\n","epoch: 6, iter:10, loss: 0.0023\n","epoch: 6, iter:20, loss: 0.0032\n","epoch: 6, iter:30, loss: 0.0022\n","epoch: 6, iter:40, loss: 0.0019\n","epoch: 6, iter:50, loss: 0.0026\n","epoch: 6, iter:60, loss: 0.0020\n","epoch: 6, iter:70, loss: 0.0022\n","epoch: 6, iter:80, loss: 0.0020\n","epoch: 6, iter:90, loss: 0.0018\n","epoch: 6, iter:100, loss: 0.0018\n","epoch: 6, iter:110, loss: 0.0013\n","epoch: 6, iter:120, loss: 0.0022\n","Finish epoch: 6, time elapsed: 329.5899\n","Start evaluation ...\n","pix_acc: 0.9937, meanIoU: 0.9870\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 7, iter: 0, loss: 0.0017\n","epoch: 7, iter:10, loss: 0.0018\n","epoch: 7, iter:20, loss: 0.0016\n","epoch: 7, iter:30, loss: 0.0019\n","epoch: 7, iter:40, loss: 0.0017\n","epoch: 7, iter:50, loss: 0.0017\n","epoch: 7, iter:60, loss: 0.0025\n","epoch: 7, iter:70, loss: 0.0020\n","epoch: 7, iter:80, loss: 0.0027\n","epoch: 7, iter:90, loss: 0.0017\n","epoch: 7, iter:100, loss: 0.0019\n","epoch: 7, iter:110, loss: 0.0017\n","epoch: 7, iter:120, loss: 0.0020\n","Finish epoch: 7, time elapsed: 329.5130\n","Start evaluation ...\n","pix_acc: 0.9938, meanIoU: 0.9870\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 8, iter: 0, loss: 0.0017\n","epoch: 8, iter:10, loss: 0.0015\n","epoch: 8, iter:20, loss: 0.0016\n","epoch: 8, iter:30, loss: 0.0016\n","epoch: 8, iter:40, loss: 0.0014\n","epoch: 8, iter:50, loss: 0.0015\n","epoch: 8, iter:60, loss: 0.0017\n","epoch: 8, iter:70, loss: 0.0020\n","epoch: 8, iter:80, loss: 0.0015\n","epoch: 8, iter:90, loss: 0.0018\n","epoch: 8, iter:100, loss: 0.0015\n","epoch: 8, iter:110, loss: 0.0014\n","epoch: 8, iter:120, loss: 0.0015\n","Finish epoch: 8, time elapsed: 329.5898\n","Start evaluation ...\n","pix_acc: 0.9938, meanIoU: 0.9871\n","Output test results ...\n","Save model ...\n","========================================\n","epoch: 9, iter: 0, loss: 0.0017\n","epoch: 9, iter:10, loss: 0.0016\n","epoch: 9, iter:20, loss: 0.0013\n","epoch: 9, iter:30, loss: 0.0016\n","epoch: 9, iter:40, loss: 0.0012\n","epoch: 9, iter:50, loss: 0.0018\n","epoch: 9, iter:60, loss: 0.0016\n","epoch: 9, iter:70, loss: 0.0014\n","epoch: 9, iter:80, loss: 0.0014\n","epoch: 9, iter:90, loss: 0.0017\n","epoch: 9, iter:100, loss: 0.0017\n","epoch: 9, iter:110, loss: 0.0015\n","epoch: 9, iter:120, loss: 0.0013\n","Finish epoch: 9, time elapsed: 329.7975\n","Start evaluation ...\n","pix_acc: 0.9936, meanIoU: 0.9867\n","Output test results ...\n","Save model ...\n","========================================\n","epoch:10, iter: 0, loss: 0.0011\n","epoch:10, iter:10, loss: 0.0014\n","epoch:10, iter:20, loss: 0.0014\n","epoch:10, iter:30, loss: 0.0018\n","epoch:10, iter:40, loss: 0.0016\n","epoch:10, iter:50, loss: 0.0016\n","epoch:10, iter:60, loss: 0.0017\n","epoch:10, iter:70, loss: 0.0015\n","epoch:10, iter:80, loss: 0.0015\n","epoch:10, iter:90, loss: 0.0015\n","epoch:10, iter:100, loss: 0.0019\n","epoch:10, iter:110, loss: 0.0013\n","epoch:10, iter:120, loss: 0.0017\n","Finish epoch:10, time elapsed: 329.6991\n","Start evaluation ...\n","pix_acc: 0.9941, meanIoU: 0.9875\n","Output test results ...\n","Save model ...\n","========================================\n","The highest mIOU is 0.9875130143320284 and is achieved at epoch-10\n","The highest pixel accuracy  is 0.9940528869628906 and is achieved at epoch-10\n"]}]},{"cell_type":"code","source":["# Used for evaluation\n","#load_path = results_path + \"/\" + \"segnet.pt\"\n","#seg_model.load_state_dict(torch.load(load_path))\n","#eval(seg_model, test_loader)"],"metadata":{"id":"HomkgRihVXsM","executionInfo":{"status":"ok","timestamp":1651753252824,"user_tz":-480,"elapsed":29,"user":{"displayName":"李杰穎","userId":"05796338728941291813"}}},"execution_count":14,"outputs":[]}]}